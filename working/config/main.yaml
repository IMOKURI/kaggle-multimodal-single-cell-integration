defaults:
  - _self_

hydra:
  run:
    dir: ../output/${now:%Y-%m-%d_%H-%M-%S}
  job:
    chdir: False
  job_logging:
    formatters:
      simple:
        format: "%(asctime)s [%(levelname)s][%(module)s] %(message)s"

wandb:
  enabled: True
  entity: imokuri
  project: msci  # Multimodal Single-Cell Integration
  dir: ../cache
  group: ${global_params.method}

settings:
  print_freq: 100
  # gpus: "0,1"

  dirs:
    working: ..
    input: ${settings.dirs.working}/input
    feature: ${settings.dirs.working}/feature
    preprocess: ${settings.dirs.working}/preprocess
    postprocess: ${settings.dirs.working}/postprocess
    # train_image: ${settings.dirs.input}/train/
    # test_image: ${settings.dirs.input}/test/
    # other_image: ${settings.dirs.input}/other/

  inputs:
    - evaluation_ids.csv
    - metadata.csv
    - sample_submission.csv

    - test_cite_inputs.h5
    - train_cite_inputs.h5
    - train_cite_targets.h5

    # - test_multi_inputs.h5
    # - train_multi_inputs.h5
    # - train_multi_targets.h5

    # - train.csv
    # - test.csv
    # - sample_submission.csv

  preprocesses:
    - train_cite_all_inputs_pca_240.pickle
    - train_cite_no_pca_inputs.pickle

    - train_cite_targets.pickle

    - test_cite_all_inputs_pca_240.pickle
    - test_cite_no_pca_inputs.pickle

    - train_multi_GL_inputs__100.pickle
    - train_multi_KI_inputs__100.pickle
    - train_multi_chr10_inputs_pca_100.pickle
    - train_multi_chr11_inputs_pca_100.pickle
    - train_multi_chr12_inputs_pca_100.pickle
    - train_multi_chr13_inputs_pca_100.pickle
    - train_multi_chr14_inputs_pca_100.pickle
    - train_multi_chr15_inputs_pca_100.pickle
    - train_multi_chr16_inputs_pca_100.pickle
    - train_multi_chr17_inputs_pca_100.pickle
    - train_multi_chr18_inputs_pca_100.pickle
    - train_multi_chr19_inputs_pca_100.pickle
    - train_multi_chr1_inputs_pca_400.pickle
    - train_multi_chr20_inputs_pca_100.pickle
    - train_multi_chr21_inputs_pca_100.pickle
    - train_multi_chr22_inputs_pca_100.pickle
    - train_multi_chr2_inputs_pca_200.pickle
    - train_multi_chr3_inputs_pca_100.pickle
    - train_multi_chr4_inputs_pca_100.pickle
    - train_multi_chr5_inputs_pca_100.pickle
    - train_multi_chr6_inputs_pca_100.pickle
    - train_multi_chr7_inputs_pca_100.pickle
    - train_multi_chr8_inputs_pca_100.pickle
    - train_multi_chr9_inputs_pca_100.pickle
    - train_multi_chrX_inputs_pca_100.pickle
    - train_multi_chrY_inputs_pca_100.pickle

    - train_multi_targets.pickle

    - test_multi_GL_inputs__100.pickle
    - test_multi_KI_inputs__100.pickle
    - test_multi_chr10_inputs_pca_100.pickle
    - test_multi_chr11_inputs_pca_100.pickle
    - test_multi_chr12_inputs_pca_100.pickle
    - test_multi_chr13_inputs_pca_100.pickle
    - test_multi_chr14_inputs_pca_100.pickle
    - test_multi_chr15_inputs_pca_100.pickle
    - test_multi_chr16_inputs_pca_100.pickle
    - test_multi_chr17_inputs_pca_100.pickle
    - test_multi_chr18_inputs_pca_100.pickle
    - test_multi_chr19_inputs_pca_100.pickle
    - test_multi_chr1_inputs_pca_400.pickle
    - test_multi_chr20_inputs_pca_100.pickle
    - test_multi_chr21_inputs_pca_100.pickle
    - test_multi_chr22_inputs_pca_100.pickle
    - test_multi_chr2_inputs_pca_200.pickle
    - test_multi_chr3_inputs_pca_100.pickle
    - test_multi_chr4_inputs_pca_100.pickle
    - test_multi_chr5_inputs_pca_100.pickle
    - test_multi_chr6_inputs_pca_100.pickle
    - test_multi_chr7_inputs_pca_100.pickle
    - test_multi_chr8_inputs_pca_100.pickle
    - test_multi_chr9_inputs_pca_100.pickle
    - test_multi_chrX_inputs_pca_100.pickle
    - test_multi_chrY_inputs_pca_100.pickle

  postprocesses:
    - evaluation_ids.csv
    - metadata.csv
    - sample_submission.csv

    - cite_inference.pickle
    # - cite_oof.pickle
    - train_cite_targets.pickle

    - multi_inference.pickle
    # - multi_oof.pickle
    # - train_multi_targets.pickle

  debug: False
  n_debug_data: 0

  amp: True
  multi_gpu: True

  skip_training: False
  skip_inference: False

  label_name: label
  n_class: 1
  scoring: pearson

# These parameters are main tuning parameters and recorded to wandb.
params:
  seed: ${global_params.seed}
  data: ${global_params.data}

global_params:
  seed: 440
  method: tabnet
  data: cite  # cite, multi

preprocess_params:
  cols: all  # all, chr1 ~ chr22, chrX, chrY, GL, KI
  methods:
    - pca
    # - ivis
  pca_n_components_cite: 240
  pca_n_components_multi: 100
  ivis_n_components_cite: 240
  ivis_n_components_multi: 100

cv_params:
  n_fold: 5
  n_validation: 1
  fold: kfold
  # group_name: patient_id
  # time_name: ""

training_params:
  epoch: 10
  es_patience: 0
  batch_size: 24
  gradient_acc_step: 1
  max_grad_norm: 1000
  # feature_set:
  #   - "f000" # f000_open_close
  criterion: CrossEntropyLoss
  optimizer: Adam
  scheduler: CosineAnnealingWarmupRestarts
  lr: 2e-2
  min_lr: 1e-5
  weight_decay: 1e-5  # AdamW: 0.01, others: 0
  # label_smoothing: 1e-6

model_params:
  dataset: base
  augmentation: light
  model: base
  model_input: 512
  model_name: tf_efficientnet_b4_ns
  # dropout: 0.0

inference_params:
  pretrained: []
  # pretrained:
  #   - dir: ""
  #     model: ""
  #     name: ""
