defaults:
  - preprocess_params
  - _self_

hydra:
  run:
    dir: ../output/${now:%Y-%m-%d_%H-%M-%S}
  job:
    chdir: False
  job_logging:
    formatters:
      simple:
        format: "%(asctime)s [%(levelname)s][%(module)s] %(message)s"

wandb:
  enabled: True
  entity: imokuri
  project: msci # Multimodal Single-Cell Integration
  dir: ../cache
  group: ${global_params.method}

settings:
  print_freq: 100
  # gpus: "0,1"

  # TODO: dirs と inputs など各ファイル名の設定を settings: から独立させて data: などとする
  dirs:
    working: ..
    input: ${settings.dirs.working}/input
    output: ${settings.dirs.working}/output
    feature: ${settings.dirs.working}/feature
    preprocess: ${settings.dirs.working}/preprocess
    postprocess: ${settings.dirs.working}/postprocess
    # train_image: ${settings.dirs.input}/train/
    # test_image: ${settings.dirs.input}/test/
    # other_image: ${settings.dirs.input}/other/

  inputs:
    - evaluation_ids.csv
    - metadata.csv
    - sample_submission.csv

    - test_cite_inputs.h5
    - test_cite_inputs_day_2_donor_27678.h5
    - train_cite_inputs.h5
    - train_cite_targets.h5

    # - test_cite_inputs_raw.h5
    # - train_cite_inputs_raw.h5
    # - train_cite_targets_raw.h5

    # - test_cite_ontology.pickle
    # - train_cite_ontology.pickle

    # - test_multi_inputs.h5
    # - train_multi_inputs.h5
    - train_multi_targets.h5

    # - test_multi_inputs_raw.h5
    # - train_multi_inputs_raw.h5
    # - train_multi_targets_raw.h5

    - multiome_target2input.csv

    # - train_multi_GL_inputs__100.pickle
    # - train_multi_KI_inputs__100.pickle
    # - train_multi_chr10_inputs_pca_100.pickle
    # - train_multi_chr11_inputs_pca_100.pickle
    # - train_multi_chr12_inputs_pca_100.pickle
    # - train_multi_chr13_inputs_pca_100.pickle
    # - train_multi_chr14_inputs_pca_100.pickle
    # - train_multi_chr15_inputs_pca_100.pickle
    # - train_multi_chr16_inputs_pca_100.pickle
    # - train_multi_chr17_inputs_pca_100.pickle
    # - train_multi_chr18_inputs_pca_100.pickle
    # - train_multi_chr19_inputs_pca_100.pickle
    # - train_multi_chr1_inputs_pca_400.pickle
    # - train_multi_chr20_inputs_pca_100.pickle
    # - train_multi_chr21_inputs_pca_100.pickle
    # - train_multi_chr22_inputs_pca_100.pickle
    # - train_multi_chr2_inputs_pca_200.pickle
    # - train_multi_chr3_inputs_pca_100.pickle
    # - train_multi_chr4_inputs_pca_100.pickle
    # - train_multi_chr5_inputs_pca_100.pickle
    # - train_multi_chr6_inputs_pca_100.pickle
    # - train_multi_chr7_inputs_pca_100.pickle
    # - train_multi_chr8_inputs_pca_100.pickle
    # - train_multi_chr9_inputs_pca_100.pickle
    # - train_multi_chrX_inputs_pca_100.pickle
    # - train_multi_chrY_inputs_pca_100.pickle
    - train_multi_nopca_inputs.pickle

    # - test_multi_GL_inputs__100.pickle
    # - test_multi_KI_inputs__100.pickle
    # - test_multi_chr10_inputs_pca_100.pickle
    # - test_multi_chr11_inputs_pca_100.pickle
    # - test_multi_chr12_inputs_pca_100.pickle
    # - test_multi_chr13_inputs_pca_100.pickle
    # - test_multi_chr14_inputs_pca_100.pickle
    # - test_multi_chr15_inputs_pca_100.pickle
    # - test_multi_chr16_inputs_pca_100.pickle
    # - test_multi_chr17_inputs_pca_100.pickle
    # - test_multi_chr18_inputs_pca_100.pickle
    # - test_multi_chr19_inputs_pca_100.pickle
    # - test_multi_chr1_inputs_pca_400.pickle
    # - test_multi_chr20_inputs_pca_100.pickle
    # - test_multi_chr21_inputs_pca_100.pickle
    # - test_multi_chr22_inputs_pca_100.pickle
    # - test_multi_chr2_inputs_pca_200.pickle
    # - test_multi_chr3_inputs_pca_100.pickle
    # - test_multi_chr4_inputs_pca_100.pickle
    # - test_multi_chr5_inputs_pca_100.pickle
    # - test_multi_chr6_inputs_pca_100.pickle
    # - test_multi_chr7_inputs_pca_100.pickle
    # - test_multi_chr8_inputs_pca_100.pickle
    # - test_multi_chr9_inputs_pca_100.pickle
    # - test_multi_chrX_inputs_pca_100.pickle
    # - test_multi_chrY_inputs_pca_100.pickle
    - test_multi_nopca_inputs.pickle

    # - train.csv
    # - test.csv
    # - sample_submission.csv

  preprocesses:
    # - train_cite_inputs.pickle
    - train_cite_no_pca_inputs.pickle
    - train_cite_ontology_pca_240.pickle
    - train_cite_ontology_pca_240_p.pickle
    - train_cite_ontology_pca_240_f.pickle
    - train_cite_ontology_pca_240_c.pickle
    # - train_cite_sum_by_rna_type_inputs.pickle
    # - train_cite_mean_by_rna_type_inputs.pickle
    # - train_cite_std_by_rna_type_inputs.pickle
    # - train_cite_skew_by_rna_type_inputs.pickle
    - train_cite_all_inputs_pca_240.pickle
    - train_cite_all_inputs_ivis_240.pickle
    # - train_cite_all_inputs_ivis_supervised_240.pickle
    - train_cite_all_inputs_scanpy_0.pickle
    # - train_cite_all_inputs_scanpy_240.pickle
    # - train_cite_all_inputs_scanpy_240_raw.pickle

    - train_cite_targets.pickle

    # - test_cite_inputs.pickle
    - test_cite_no_pca_inputs.pickle
    - test_cite_ontology_pca_240.pickle
    - test_cite_ontology_pca_240_p.pickle
    - test_cite_ontology_pca_240_f.pickle
    - test_cite_ontology_pca_240_c.pickle
    # - test_cite_sum_by_rna_type_inputs.pickle
    # - test_cite_mean_by_rna_type_inputs.pickle
    # - test_cite_std_by_rna_type_inputs.pickle
    # - test_cite_skew_by_rna_type_inputs.pickle
    - test_cite_all_inputs_pca_240.pickle
    - test_cite_all_inputs_ivis_240.pickle
    # - test_cite_all_inputs_ivis_supervised_240.pickle
    - test_cite_all_inputs_scanpy_0.pickle
    # - test_cite_all_inputs_scanpy_240.pickle
    # - test_cite_all_inputs_scanpy_240_raw.pickle

    - train_multi_GL_inputs__100.pickle
    - train_multi_KI_inputs__100.pickle
    - train_multi_chr10_inputs_pca_100.pickle
    - train_multi_chr11_inputs_pca_100.pickle
    - train_multi_chr12_inputs_pca_100.pickle
    - train_multi_chr13_inputs_pca_100.pickle
    - train_multi_chr14_inputs_pca_100.pickle
    - train_multi_chr15_inputs_pca_100.pickle
    - train_multi_chr16_inputs_pca_100.pickle
    - train_multi_chr17_inputs_pca_100.pickle
    - train_multi_chr18_inputs_pca_100.pickle
    - train_multi_chr19_inputs_pca_100.pickle
    - train_multi_chr1_inputs_pca_400.pickle
    - train_multi_chr20_inputs_pca_100.pickle
    - train_multi_chr21_inputs_pca_100.pickle
    - train_multi_chr22_inputs_pca_100.pickle
    - train_multi_chr2_inputs_pca_200.pickle
    - train_multi_chr3_inputs_pca_100.pickle
    - train_multi_chr4_inputs_pca_100.pickle
    - train_multi_chr5_inputs_pca_100.pickle
    - train_multi_chr6_inputs_pca_100.pickle
    - train_multi_chr7_inputs_pca_100.pickle
    - train_multi_chr8_inputs_pca_100.pickle
    - train_multi_chr9_inputs_pca_100.pickle
    - train_multi_chrX_inputs_pca_100.pickle
    - train_multi_chrY_inputs_pca_100.pickle

    - train_multi_all_inputs_ivis_240.pickle
    - train_multi_nopca_inputs_ivis_240.pickle

    - train_multi_targets.pickle

    - test_multi_GL_inputs__100.pickle
    - test_multi_KI_inputs__100.pickle
    - test_multi_chr10_inputs_pca_100.pickle
    - test_multi_chr11_inputs_pca_100.pickle
    - test_multi_chr12_inputs_pca_100.pickle
    - test_multi_chr13_inputs_pca_100.pickle
    - test_multi_chr14_inputs_pca_100.pickle
    - test_multi_chr15_inputs_pca_100.pickle
    - test_multi_chr16_inputs_pca_100.pickle
    - test_multi_chr17_inputs_pca_100.pickle
    - test_multi_chr18_inputs_pca_100.pickle
    - test_multi_chr19_inputs_pca_100.pickle
    - test_multi_chr1_inputs_pca_400.pickle
    - test_multi_chr20_inputs_pca_100.pickle
    - test_multi_chr21_inputs_pca_100.pickle
    - test_multi_chr22_inputs_pca_100.pickle
    - test_multi_chr2_inputs_pca_200.pickle
    - test_multi_chr3_inputs_pca_100.pickle
    - test_multi_chr4_inputs_pca_100.pickle
    - test_multi_chr5_inputs_pca_100.pickle
    - test_multi_chr6_inputs_pca_100.pickle
    - test_multi_chr7_inputs_pca_100.pickle
    - test_multi_chr8_inputs_pca_100.pickle
    - test_multi_chr9_inputs_pca_100.pickle
    - test_multi_chrX_inputs_pca_100.pickle
    - test_multi_chrY_inputs_pca_100.pickle

    - test_multi_all_inputs_ivis_240.pickle
    - test_multi_nopca_inputs_ivis_240.pickle

    - metadata.pickle

    - cite_adversarial_oof.pickle
    - multi_adversarial_oof.pickle

  postprocesses:
    - evaluation_ids.csv
    - metadata.csv
    - sample_submission.csv

    # - cite_inference.pickle
    # - cite_oof.pickle
    - cite_adversarial_oof.pickle
    - train_cite_targets.pickle

    # - multi_inference.pickle
    # - multi_oof.pickle
    - multi_adversarial_oof.pickle
    - train_multi_targets.pickle

  debug: False
  n_debug_data: 0

  amp: True
  multi_gpu: True

  skip_training: False
  skip_inference: False # ** adversarial

  label_name: label # label  # ** cell_type_num
  n_class: 1
  scoring: pearson # pearson, accuracy  # ** adversarial

params:
  # seed: ${global_params.seed}
  data: ${global_params.data}

global_params:
  # seed: 440
  method: xgboost # tuning_tabnet, adversarial_tabnet  # ** adversarial
  data: cite # cite, multi

cv_params:
  n_fold: 7
  n_validation: 1
  fold: stratified
  group_name: donor
  # time_name: ""

training_params:
  epoch: 20
  es_patience: 20
  batch_size: 2048
  gradient_acc_step: 1
  max_grad_norm: 1000
  # feature_set:
  #   - "f000" # f000_open_close
  criterion: PearsonCCLoss # PearsonCCLoss, RMSELoss
  optimizer: Adam
  scheduler: CosineAnnealingWarmRestarts
  lr: 2e-2
  min_lr: 1e-5
  weight_decay: 1e-5 # AdamW: 0.01, others: 0
  # label_smoothing: 1e-6

  use_cell_type: True
  tabnet:
    pre_training: True

model_params:
  dataset: table_base
  model: one_d_cnn
  model_name: one_d_cnn
  model_input: 0
  tf_initialization: False
  tabnet:
    n_d: 56
    n_steps: 1
    n_independent: 1
    gamma: 1.6
    mask_type: entmax
    cite:
      n_d: 64
      n_steps: 1
      n_independent: 1
      gamma: 1.9
      mask_type: entmax
    multi:
      n_d: 64
      n_steps: 1
      n_independent: 1
      gamma: 1.3
      mask_type: entmax
  one_d_cnn:
    hidden_size: 4096
    ch_1: 256
    ch_2: 512
    ch_3: 512
    dropout_1: 0.1
    dropout_2: 0.2
    dropout_3: 0.1
    weight_norm: True
    cite:
      hidden_size: 1024
      ch_1: 128
      ch_2: 384
      ch_3: 384
      dropout_1: 0.05
      dropout_2: 0.2
      dropout_3: 0.1
      weight_norm: True
    multi:
      hidden_size: 8192
      ch_1: 256
      ch_2: 512
      ch_3: 512
      dropout_1: 0.1
      dropout_2: 0.2
      dropout_3: 0.1
      weight_norm: True

inference_params:
  cite_ensemble_weight_optimization: False
  multi_ensemble_weight_optimization: False
  main_submission_weight: 2
  cite_pretrained:
    2022-10-15_01-16-43: 0.47 # 0.18 # 0.55 # 0.24 # MLP_tf dropout 0.90198 by 686, seed 1440
    2022-10-15_01-34-34: 0.17 # 0.13 # 0.18 # 0.15 # MLP resnet 0.90139 by 686
    2022-10-15_12-39-39: 0.15 # 0.2  # 0.33 # 0.21 # 1D CNN 0.90189 by 686
    2022-10-15_12-50-55: 0.13 # 0.19 # 0.38 # 0.32 # 1D CNN 0.90175 by 686
    2022-10-14_03-16-10: 0.09 # 0.47 # 0.63 # 0.70 # xgboost 0.89997 by 687
    2022-10-18_00-16-49: 0.06 # 0.98 # 0.94 # 0.91 # xgboost 0.89998 by 687
    2022-10-27_12-50-48: 0.56 # 0.19 # 0.54 # 0.39 # tabnet 0.90283 by 407
    2022-10-27_12-55-11: 0.39 # 0.54 # 0.17 # 0.3  # tabnet 0.90291 by 407
    2022-10-28_14-34-19: 0.37 # 0.68 # 0.73 # 0.93 # tabnet 56-1-1-1.9 0.90298 by 407
    2022-10-28_14-46-38: 0.97 # 0.96 # 0.75 # 0.78 # tabnet 56-1-1-1.9 0.90293 by 407
    2022-10-28_14-52-22: 0.70 # 0.85 # 0.77 # 0.9  # tabnet 64-1-1-1.9 0.90301 by 407
    2022-10-28_14-54-39: 0.71 # 0.86 # 0.95 # 0.36 # tabnet 64-1-1-1.9 0.90305 by 407
    2022-10-30_03-45-35: 0.73 # 0.67 # 0.93 # 0.9  # tabnet 0.90307 by 507
    2022-10-30_03-47-04: 0.13 # 0.58 # 0.67 # 0.5  # tabnet 0.90302 by 507
    2022-10-30_04-05-42: 0.70 # 0.56 # 0.88 # 0.86 # tabnet 0.90304 by 507
    2022-10-30_04-48-37: 0.56 # 0.61 # 0.79 # 0.4  # dropout 0.90265 by 506
    2022-10-30_13-54-14: 0.02 # tabnet 0.90280 by 707
    2022-10-30_13-54-31: 0.34 # tabnet 0.90296 by 707
    2022-10-27_13-54-13: 0.53 # xgboost 0.90019 by 407
    2022-10-27_13-55-23: 0.66 # xgboost 0.90021 by 407
  multi_pretrained:
    2022-10-16_13-08-46: 1 # 1D CNN_tf 0.67085 by 3344
    2022-10-16_13-30-35: 1 # 1D CNN 0.67086 by 3344
    2022-10-17_00-25-56: 1 # 1D CNN 0.67076 by 3104
    2022-10-17_13-19-49: 1 # 1D CNN_tf 0.67069 by 3104
    2022-10-30_00-30-35: 1 # 1D CNN 0.67084 by 3344 ch 8192
    # 2022-10-07_06-25-40: 1  # tabnet 0.66899 by 3104
    # 2022-10-07_06-15-47: 1  # tabnet 0.66904 by 3105
    # 2022-10-07_12-36-15: 1  # tabnet 0.66900 by 3105, seed 1440
    # 2022-10-11_03-22-34: 1  # tabnet 0.66918 by 3105, pretrain with train data
    # 2022-10-11_03-26-46: 1  # tabnet 0.66902 by 3105, pretrain with all data
    # 2022-10-14_09-27-14: 1  # tabnet 0.66902 by 3345, pretrain with all data
    # 2022-10-14_12-20-29: 1  # tabnet 0.66903 by 3345, pretrain with all data, seed 2440
    # 2022-10-19_06-59-06: 1  # tabnet 0.66951 by 3345, pretrain with all data
    # 2022-10-19_22-19-09: 1  # tabnet 0.66945 by 3345, pretrain with all data
  pretrained:
    5-5-msci22-ensembling-citeseq: 1 # 0.812
    all-in-one-citeseq-multiome-with-keras: 1 # 0.812
    uehara-san-2022-10-28-0749: 1 # 0.811
  # pretrained:
  #   - dir: ""
  #     model: ""
  #     name: ""
